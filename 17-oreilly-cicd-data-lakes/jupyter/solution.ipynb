{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14790dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|value                                                                                                                                                                  |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|# Welcome to the lakeFS data challenge! You've found the first dataset to explore.                                                                                     |\n",
      "|                                                                                                                                                                       |\n",
      "|In order to succeed you'd need to know the following:                                                                                                                  |\n",
      "|                                                                                                                                                                       |\n",
      "|1. Familiarity with Spark (using pySpark) and Jupyter notebooks                                                                                                        |\n",
      "|2. Basic understanding of lakeFS - a good place to start is https://docs.lakefs.io/                                                                                    |\n",
      "|                                                                                                                                                                       |\n",
      "|Your challenge, should you agree to accept it, is do accomplish the following:                                                                                         |\n",
      "|                                                                                                                                                                       |\n",
      "|1. On the main branch, find the users that have done less than 50 events.                                                                                              |\n",
      "|2. The events table has a new version available, on the `improvedDataJune2020` branch!                                                                                 |\n",
      "|3. Find the number of users that have over 50 events in this new version, but that had less than 50 events on main! Only count users that have events in BOTH versions.|\n",
      "|4. This number opens a treasure chest! you'll need to find it and use it to unlock the chest and complete the challenge                                                |\n",
      "|                                                                                                                                                                       |\n",
      "|To open the lakeFS UI and start exploring:                                                                                                                             |\n",
      "|                                                                                                                                                                       |\n",
      "|URL: http://localhost:8010/                                                                                                                                            |\n",
      "|Access Key ID: AKIAIOSFODNN7EXAMPLE                                                                                                                                    |\n",
      "|Secret Access Key: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY                                                                                                            |\n",
      "|                                                                                                                                                                       |\n",
      "|Good luck!                                                                                                                                                             |\n",
      "|                                                                                                                                                                       |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"lakeFSNotebook\") \\\n",
    "    .master(\"local[1]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "instructions = spark.read.text(\"lakefs://oreilly-challenge/main/instructions.txt\")\n",
    "instructions.show(instructions.count(), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aab5ad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = spark.read.parquet(f'lakefs://oreilly-challenge/main/datasets/users/*.parquet')\n",
    "events = spark.read.parquet(f'lakefs://oreilly-challenge/main/datasets/user_events/EventType=*/*.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "347f47ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|  UID|count|\n",
      "+-----+-----+\n",
      "|42852|   89|\n",
      "|43367|   99|\n",
      "|44342|    7|\n",
      "|44901|   91|\n",
      "|45726|   25|\n",
      "|48280|    2|\n",
      "|48603|    6|\n",
      "|48899|    3|\n",
      "|49326|    1|\n",
      "|49586|   25|\n",
      "|49754|   91|\n",
      "|49967|    2|\n",
      "|50124|   99|\n",
      "|50287|   89|\n",
      "|51056|    6|\n",
      "|52001|    7|\n",
      "|52051|   99|\n",
      "|52611|    6|\n",
      "|52743|    6|\n",
      "|52910|    6|\n",
      "+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------+\n",
      "|max(count)|\n",
      "+----------+\n",
      "|        99|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "exprs = [F.max(x) for x in [\"count\"]]\n",
    "countEventsDF = events.groupBy(\"UID\").count()\n",
    "countEventsDF.show()\n",
    "countEventsDF.agg(*exprs).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f957c854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|  UID|count|\n",
      "+-----+-----+\n",
      "|44342|    7|\n",
      "|45726|   25|\n",
      "|48280|    2|\n",
      "|48603|    6|\n",
      "|48899|    3|\n",
      "|49326|    1|\n",
      "|49586|   25|\n",
      "|49967|    2|\n",
      "|51056|    6|\n",
      "|52001|    7|\n",
      "|52611|    6|\n",
      "|52743|    6|\n",
      "|52910|    6|\n",
      "|53294|    3|\n",
      "|53721|    6|\n",
      "|54039|    6|\n",
      "|54415|    1|\n",
      "|54536|   25|\n",
      "|54660|    2|\n",
      "|55426|    6|\n",
      "+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "less_than_50 = countEventsDF.filter(countEventsDF[\"count\"] < 50)\n",
    "less_than_50.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2886947c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|  UID|count|\n",
      "+-----+-----+\n",
      "|15194|   91|\n",
      "|15322|   89|\n",
      "|17048|   99|\n",
      "|18147|   91|\n",
      "|18196|   91|\n",
      "|18295|   89|\n",
      "|19158|   89|\n",
      "|19907|   91|\n",
      "|21223|   89|\n",
      "|21342|   89|\n",
      "|  964|   89|\n",
      "| 1697|   91|\n",
      "| 1806|   91|\n",
      "| 2250|   89|\n",
      "| 2927|   89|\n",
      "| 4590|   99|\n",
      "| 5385|   89|\n",
      "|37310|   89|\n",
      "|38287|   91|\n",
      "|38543|   99|\n",
      "+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[UID: bigint, count: bigint]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events = spark.read.parquet(f'lakefs://oreilly-challenge/improvedDataJune2020/datasets/user_events/EventType=*/*.parquet').groupBy(\"UID\").count()\n",
    "more_than_50 = events.filter(events[\"count\"] > 50)\n",
    "more_than_50.show()\n",
    "more_than_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4dce3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+-----+\n",
      "|UID|count|UID|count|\n",
      "+---+-----+---+-----+\n",
      "|  0|   99|  0|    6|\n",
      "|  1|   89|  1|    2|\n",
      "|  9|   91|  9|    7|\n",
      "| 14|   99| 14|    6|\n",
      "| 21|   89| 21|    3|\n",
      "| 28|   99| 28|    2|\n",
      "| 31|   91| 31|    2|\n",
      "| 33|   99| 33|    7|\n",
      "| 35|   91| 35|    2|\n",
      "| 53|   91| 53|    6|\n",
      "| 54|   89| 54|    1|\n",
      "| 82|   89| 82|    1|\n",
      "|102|   99|102|    2|\n",
      "|113|   91|113|    1|\n",
      "|114|   99|114|    6|\n",
      "|120|   99|120|   25|\n",
      "|130|   89|130|    2|\n",
      "|157|   91|157|    6|\n",
      "|160|   99|160|    1|\n",
      "|180|   91|180|   25|\n",
      "+---+-----+---+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined = more_than_50.join(less_than_50, more_than_50[\"UID\"] == less_than_50[\"UID\"],\"inner\")\n",
    "joined.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83d28809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103351"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c35b364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------+\n",
      "|Chest                 |Key   |\n",
      "+----------------------+------+\n",
      "|https://bit.ly/3QbH1Rn|103351|\n",
      "+----------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prizes = spark.read.parquet(f'lakefs://oreilly-challenge/prizes/datasets/treasure_chests/*.parquet')\n",
    "prizes.filter(prizes[\"Key\"] == 103351).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5731b182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
