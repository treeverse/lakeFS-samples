{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2871c4c7",
   "metadata": {},
   "source": [
    "<img src=\"./images/logo.svg\" alt=\"lakeFS logo\" width=300/> \n",
    "\n",
    "# ML Experimentation 02 (Wine Quality)\n",
    "\n",
    "In this tutorial, you will learn how to version your ML training data, model artifacts, metrics and your training code together with lakeFS. We will be using [Wine-Quality-Dataset](https://archive.ics.uci.edu/ml/datasets/wine+quality) for the multi class classification \n",
    "\n",
    "To learn more about how lakeFS can be used for ML experimentation and reproducibility, check out the [published blog](https://lakefs.io/blog/building-an-ml-experimentation-platform-for-easy-reproducibility-using-lakefs/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251d5405",
   "metadata": {},
   "source": [
    "## Config\n",
    "\n",
    "**_If you're not using the provided lakeFS server and MinIO storage then change these values to match your environment_**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e50753",
   "metadata": {},
   "source": [
    "### lakeFS endpoint and credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab50223",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefsEndPoint = 'http://lakefs:8000' # e.g. 'https://username.aws_region_name.lakefscloud.io' \n",
    "lakefsAccessKey = 'AKIAIOSFOLKFSSAMPLES'\n",
    "lakefsSecretKey = 'wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3275a1",
   "metadata": {},
   "source": [
    "### Object Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bc8b9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "storageNamespace = 's3://example' # e.g. \"s3://bucket\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575c81d5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5ba145",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "**(you shouldn't need to change anything in this section, just run it)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17b81bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repo_name = \"ml-experimentation-wine-quality\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d9b7d0-b45e-4460-833d-05c78bec5251",
   "metadata": {},
   "source": [
    "### Versioning Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd94a29-fed1-45c3-9e5f-262418b44859",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ingest_branch = \"ingest-data\"\n",
    "prod_branch = \"main\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29623c6-0870-4368-8e14-e1c78d927987",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ae1483-bba5-4c66-941e-6503debf8ff4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import lakefs\n",
    "from assets.lakefs_demo import print_commit, print_diff\n",
    "from datetime import date, time, datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7239dca6",
   "metadata": {},
   "source": [
    "### Set environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d0d465",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"LAKECTL_SERVER_ENDPOINT_URL\"] = lakefsEndPoint\n",
    "os.environ[\"LAKECTL_CREDENTIALS_ACCESS_KEY_ID\"] = lakefsAccessKey\n",
    "os.environ[\"LAKECTL_CREDENTIALS_SECRET_ACCESS_KEY\"] = lakefsSecretKey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30db010",
   "metadata": {},
   "source": [
    "#### Verify lakeFS credentials by getting lakeFS version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0288ecd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Verifying lakeFS credentialsâ€¦\")\n",
    "try:\n",
    "    v=lakefs.client.Client().version\n",
    "except:\n",
    "    print(\"ðŸ›‘ failed to get lakeFS version\")\n",
    "else:\n",
    "    print(f\"â€¦âœ…lakeFS credentials verified\\n\\nâ„¹ï¸lakeFS version {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5f17b5",
   "metadata": {},
   "source": [
    "### Define lakeFS Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe1b04f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repo = lakefs.Repository(repo_name).create(storage_namespace=f\"{storageNamespace}/{repo_name}\", default_branch=prod_branch, exist_ok=True)\n",
    "branchProd = repo.branch(prod_branch)\n",
    "print(repo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c314f9c2-f073-406e-8327-c4b71670437a",
   "metadata": {},
   "source": [
    "### Install and Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d739edf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# boto3 is re-installed here due to issue detailed in https://github.com/boto/boto3/issues/3648\n",
    "! pip install duckdb s3fs boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef803a82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import io\n",
    "import csv\n",
    "import duckdb\n",
    "import s3fs\n",
    "import json\n",
    "import tempfile\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eaf293",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffa3efd-2c1c-4e0f-acb2-ec84ea5f2744",
   "metadata": {},
   "source": [
    "### Configure boto3 client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c356ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3',\n",
    "    endpoint_url=lakefsEndPoint,\n",
    "    aws_access_key_id=lakefsAccessKey,\n",
    "    aws_secret_access_key=lakefsSecretKey)\n",
    "\n",
    "s3_resource = boto3.resource('s3',\n",
    "    endpoint_url=lakefsEndPoint,\n",
    "    aws_access_key_id=lakefsAccessKey,\n",
    "    aws_secret_access_key=lakefsSecretKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5952a460",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3 = s3fs.S3FileSystem(anon=False,\n",
    "                      key=lakefsAccessKey,\n",
    "                      secret=lakefsSecretKey,\n",
    "                      client_kwargs={'endpoint_url': lakefsEndPoint})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f4e0b6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744be8ac",
   "metadata": {},
   "source": [
    "# Main Tutorial starts here ðŸš¦ ðŸ‘‡ðŸ»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d07acc4",
   "metadata": {},
   "source": [
    "# Creating Ingest branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2acbc7-acdd-4a67-82a2-387198781196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "branchIngest = repo.branch(ingest_branch).create(source_reference=prod_branch, exist_ok=True)\n",
    "print(f\"{ingest_branch} ref:\", branchIngest.get_commit().id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb22215b",
   "metadata": {},
   "source": [
    "# Upload wine-quality-dataset to ingest branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897649d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ingest_data = \"wine-quality-white-and-red.csv\"\n",
    "ingest_path = f'dt={str(date.today())}/raw/{ingest_data}' \n",
    "ingest_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796de113-b3e0-4c96-ba4e-39243742da27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "contentToUpload = open(f'/data/{ingest_data}', 'r').read()\n",
    "branchIngest.object(ingest_path).upload(data=contentToUpload, mode='wb', pre_sign=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bada0c-2722-4f16-88f1-acda349f5923",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_diff(branchIngest.uncommitted())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb27dd2-0a76-4cd7-bf33-72877799caca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref = branchIngest.commit(message=\"wine quality data uploaded to ingest branch\")\n",
    "print_commit(ref.get_commit())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf4dd66",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c40a330",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filepath = f\"s3://{repo_name}/{ingest_branch}/{ingest_path}\"\n",
    "print(filepath)\n",
    "\n",
    "obj = s3_client.get_object(Bucket=repo_name, Key=f'{ingest_branch}/{ingest_path}')\n",
    "wine_df = pd.read_csv(io.BytesIO(obj['Body'].read()), header='infer')\n",
    "wine_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76cf3c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fb4ddf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.pairplot(wine_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17376a20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Counter(wine_df['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2b2457",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='quality', data=wine_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db7cf1f",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4914f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scale_input(x):\n",
    "    sc = StandardScaler()\n",
    "    x = sc.fit_transform(x)\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcb2ba0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_pca(pca):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_), 'ro-')\n",
    "    plt.grid()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5292c3",
   "metadata": {},
   "source": [
    "# Experimentation Begins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e842d8",
   "metadata": {},
   "source": [
    "# Experiment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dda0ce2",
   "metadata": {},
   "source": [
    "- Preprocess - Standard Scaler, PCA\n",
    "- Training - RandomForestClassifier\n",
    "- Evaluation - F1 score\n",
    "- Labels - Multiclass classification (quality: 1 to 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1afec1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'branch_name': 'exp-1',\n",
    "    'drop_columns': ['type'],\n",
    "    'f1_average': 'micro', #imbalance class problem\n",
    "    'is_scale_input': True,\n",
    "    'is_pca': True,\n",
    "    'test_size': '0.25'\n",
    "}\n",
    "params1 = config\n",
    "\n",
    "filepath = f\"s3://{repo_name}/{params1['branch_name']}/{ingest_path}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be968799",
   "metadata": {},
   "source": [
    "### Create new branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd52883d-038d-43c9-a253-a00d0c9ee7f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "branchExp1 = repo.branch(params1['branch_name']).create(source_reference=ingest_branch, exist_ok=True)\n",
    "print(f\"{params1['branch_name']} ref:\", branchExp1.get_commit().id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ddc105",
   "metadata": {},
   "source": [
    "### Save configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3820da59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_df = pd.DataFrame.from_dict(params1)\n",
    "config_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0d689a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with s3.open(f\"/{repo_name}/{params1['branch_name']}/dt={str(date.today())}/config/config.csv\",'w') as f:\n",
    "    config_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d90cc96-77a9-4051-beab-c54c551f817e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref = branchExp1.commit(message=\"Uploaded training configs\")\n",
    "print_commit(ref.get_commit())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2c03e7",
   "metadata": {},
   "source": [
    "### Create model features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb35e42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obj = s3_client.get_object(Bucket=repo_name, Key=f\"{params1['branch_name']}/{ingest_path}\")\n",
    "wine_df = pd.read_csv(io.BytesIO(obj['Body'].read()), header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455945c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fc98c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wine_df.drop(columns=['type'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d35037",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = wine_df.iloc[:,:11]\n",
    "y = wine_df['quality']\n",
    "y_col = ['quality']\n",
    "x_cols = [col for col in x.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb371793",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if params1['is_scale_input']:\n",
    "    x = scale_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d467a06c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5fc611",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if params1['is_pca']:\n",
    "    pca = PCA()\n",
    "    x_pca = pca.fit_transform(x)\n",
    "    plot_pca(pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0454a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if params1['is_pca']:\n",
    "    n_comp = 6\n",
    "    pca_new = PCA(n_components=n_comp)\n",
    "    x = pca_new.fit_transform(x)\n",
    "    x_cols = [f\"pca_{i}\" for i in range(n_comp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecedcd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7387d6d",
   "metadata": {},
   "source": [
    "### Save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc99e36b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = pd.DataFrame(x, columns = x_cols)\n",
    "label = pd.DataFrame(y, columns = y_col)\n",
    "\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e5c148",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddcc121",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with s3.open(f\"/{repo_name}/{params1['branch_name']}/dt={str(date.today())}/features/features.csv\",'w') as f:\n",
    "    features.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1a17c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with s3.open(f\"/{repo_name}/{params1['branch_name']}/dt={str(date.today())}/features/label.csv\",'w') as f:\n",
    "    label.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfde851b-006c-4704-a8c8-99914b28e35a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref = branchExp1.commit(message=\"Uploaded features\")\n",
    "print_commit(ref.get_commit())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d452ff",
   "metadata": {},
   "source": [
    "### Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760a8260",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "x_train = pd.DataFrame(x_train, columns = x_cols)\n",
    "x_test = pd.DataFrame(x_test, columns = x_cols)\n",
    "y_train = pd.DataFrame(y_train, columns = y_col)\n",
    "y_test = pd.DataFrame(y_test, columns = y_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15257f1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db104eb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with s3.open(f\"/{repo_name}/{params1['branch_name']}/dt={str(date.today())}/preprocessed/x_train.csv\",'w') as f:\n",
    "    x_train.to_csv(f)\n",
    "    \n",
    "    \n",
    "with s3.open(f\"/{repo_name}/{params1['branch_name']}/dt={str(date.today())}/preprocessed/x_test.csv\",'w') as f:\n",
    "    x_test.to_csv(f)\n",
    "    \n",
    "    \n",
    "with s3.open(f\"/{repo_name}/{params1['branch_name']}/dt={str(date.today())}/preprocessed/y_train.csv\",'w') as f:\n",
    "    y_train.to_csv(f)\n",
    "    \n",
    "    \n",
    "with s3.open(f\"/{repo_name}/{params1['branch_name']}/dt={str(date.today())}/preprocessed/y_test.csv\",'w') as f:\n",
    "    y_test.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1890a9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)\n",
    "rf_predict=rf.predict(x_test)\n",
    "\n",
    "rf_conf_matrix = confusion_matrix(y_test, rf_predict)\n",
    "rf_f1_score = f1_score(y_test, rf_predict, average=params1['f1_average'])\n",
    "print(rf_conf_matrix)\n",
    "print(\"\\nF1-score: \\t\", round(rf_f1_score*100,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24490dd",
   "metadata": {},
   "source": [
    "### Save model artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05301a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_file = os.path.join(f\"s3://{repo_name}/{params1['branch_name']}/dt={str(date.today())}/artifacts/\", \"model.joblib\")\n",
    "print(output_file)\n",
    "\n",
    "with s3.open(output_file, 'wb') as f:\n",
    "    joblib.dump(rf, f) \n",
    "\n",
    "# # Read\n",
    "# with s3.open(output_file, 'rb') as f:\n",
    "#     rf = joblib.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ed2421-2ed9-403b-9829-6add01f414a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref = branchExp1.commit(message=\"Uploaded model artifacts\")\n",
    "print_commit(ref.get_commit())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9748ee0",
   "metadata": {},
   "source": [
    "### Save model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6b2296",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame.from_dict({'f1': [rf_f1_score]})\n",
    "with s3.open(f\"/{repo_name}/{params1['branch_name']}/dt={str(date.today())}/metrics/scores.csv\",'w') as f:\n",
    "    metrics_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058c5ab0-010a-4765-9855-de2adef37f29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref = branchExp1.commit(message=\"Uploaded training metrics\")\n",
    "print_commit(ref.get_commit())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218a4dd7",
   "metadata": {},
   "source": [
    "# Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a690bb05",
   "metadata": {},
   "source": [
    "- Preprocess - Regroup labels\n",
    "- Training - RandomForestClassifier\n",
    "- Evaluation - F1 score\n",
    "- Labels - Multiclass classification (quality: Bad, Okay, Good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f96df3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'branch_name': 'exp-2',\n",
    "    'drop_columns': ['type'],\n",
    "    'f1_average': 'weighted', #imbalance class problem\n",
    "    'is_scale_input': False,\n",
    "    'is_pca': False,\n",
    "    'test_size': '0.25'\n",
    "}\n",
    "params2 = config\n",
    "\n",
    "filepath = f\"s3://{repo_name}/{params2['branch_name']}/{ingest_path}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65107bda",
   "metadata": {},
   "source": [
    "### Create new branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8329684e-ff92-4a86-b31a-b97899a1328b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "branchExp2 = repo.branch(params2['branch_name']).create(source_reference=ingest_branch, exist_ok=True)\n",
    "print(f\"{params2['branch_name']} ref:\", branchExp2.get_commit().id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c6aa71",
   "metadata": {},
   "source": [
    "### Save configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16a3028",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_df = pd.DataFrame.from_dict(params2)\n",
    "config_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d108ec75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with s3.open(f\"/{repo_name}/{params2['branch_name']}/dt={str(date.today())}/config/config.csv\",'w') as f:\n",
    "    config_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5050108b-8e6d-43f7-ad9a-de167044013a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref = branchExp2.commit(message=\"Uploaded training configs\")\n",
    "print_commit(ref.get_commit())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c032e7c",
   "metadata": {},
   "source": [
    "### Create model features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72be7af8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obj = s3_client.get_object(Bucket=repo_name, Key=f\"{params2['branch_name']}/{ingest_path}\")\n",
    "wine_df = pd.read_csv(io.BytesIO(obj['Body'].read()), header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482d2546",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9eb7d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wine_df.drop(columns=['type'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3550dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reviews = []\n",
    "for i in wine_df['quality']:\n",
    "    if i >= 1 and i <= 3:\n",
    "        reviews.append('1')\n",
    "    elif i >= 4 and i <= 6:\n",
    "        reviews.append('2')\n",
    "    elif i >= 7 and i <= 10:\n",
    "        reviews.append('3')\n",
    "wine_df['reviews'] = reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be61f108",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = wine_df.iloc[:,:11]\n",
    "y = wine_df['reviews']\n",
    "y_col = ['reviews']\n",
    "x_cols = [col for col in x.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99ee196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4304c7e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28660bf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.countplot(x=y, data=wine_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f2af22",
   "metadata": {},
   "source": [
    "### Save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126b24be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = pd.DataFrame(x, columns = x_cols)\n",
    "label = pd.DataFrame(y, columns = y_col)\n",
    "\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762f5511",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806b4483",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with s3.open(f\"/{repo_name}/{params2['branch_name']}/dt={str(date.today())}/features/features.csv\",'w') as f:\n",
    "    features.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2732865",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with s3.open(f\"/{repo_name}/{params2['branch_name']}/dt={str(date.today())}/features/label.csv\",'w') as f:\n",
    "    label.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1581a01a-3331-49ef-a87c-5b15518ced80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref = branchExp2.commit(message=\"Uploaded features\")\n",
    "print_commit(ref.get_commit())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86f8fbb",
   "metadata": {},
   "source": [
    "### Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18d7ff1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "x_train = pd.DataFrame(x_train, columns = x_cols)\n",
    "x_test = pd.DataFrame(x_test, columns = x_cols)\n",
    "y_train = pd.DataFrame(y_train, columns = y_col)\n",
    "y_test = pd.DataFrame(y_test, columns = y_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b339c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with s3.open(f\"/{repo_name}/{params2['branch_name']}/dt={str(date.today())}/preprocessed/x_train.csv\",'w') as f:\n",
    "    x_train.to_csv(f)\n",
    "    \n",
    "    \n",
    "with s3.open(f\"/{repo_name}/{params2['branch_name']}/dt={str(date.today())}/preprocessed/x_test.csv\",'w') as f:\n",
    "    x_test.to_csv(f)\n",
    "    \n",
    "    \n",
    "with s3.open(f\"/{repo_name}/{params2['branch_name']}/dt={str(date.today())}/preprocessed/y_train.csv\",'w') as f:\n",
    "    y_train.to_csv(f)\n",
    "    \n",
    "    \n",
    "with s3.open(f\"/{repo_name}/{params2['branch_name']}/dt={str(date.today())}/preprocessed/y_test.csv\",'w') as f:\n",
    "    y_test.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a5ec66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)\n",
    "rf_predict=rf.predict(x_test)\n",
    "\n",
    "rf_conf_matrix = confusion_matrix(y_test, rf_predict)\n",
    "rf_f1_score = f1_score(y_test, rf_predict, average='weighted')\n",
    "print(rf_conf_matrix)\n",
    "print(\"F1-score: \\t\", round(rf_f1_score*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623def87",
   "metadata": {},
   "source": [
    "### Save model artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdac0644",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_file = os.path.join(f\"s3://{repo_name}/{params2['branch_name']}/dt={str(date.today())}/artifacts/\", \"model.joblib\")\n",
    "print(output_file)\n",
    "\n",
    "with s3.open(output_file, 'wb') as f:\n",
    "    joblib.dump(rf, f) \n",
    "\n",
    "# # Read\n",
    "# with s3.open(output_file, 'rb') as f:\n",
    "#     rf = joblib.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ad4593-c507-4d56-9b4a-19cc90c0d493",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref = branchExp2.commit(message=\"Uploaded model artifacts\")\n",
    "print_commit(ref.get_commit())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa126f1f",
   "metadata": {},
   "source": [
    "### Save model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a4b160",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame.from_dict({'f1': [rf_f1_score]})\n",
    "with s3.open(f\"/{repo_name}/{params2['branch_name']}/dt={str(date.today())}/metrics/scores.csv\",'w') as f:\n",
    "    metrics_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc56f149-4580-4534-839e-3f4d21934a74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref = branchExp2.commit(message=\"Uploaded training metrics\")\n",
    "print_commit(ref.get_commit())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc9722b",
   "metadata": {},
   "source": [
    "### Reproduce an experiment with lakeFS tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51130d1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tag_branch = \"exp-1\"\n",
    "tag = f'{datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")}_{tag_branch}'\n",
    "tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1c8bb7-cd43-490b-be27-27de5fb96528",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefs.Tag(repo_name, tag).create(tag_branch, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5385c729",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_path = f\"{tag}/dt={str(date.today())}/features/features.csv\"\n",
    "label_path = f\"{tag}/dt={str(date.today())}/features/label.csv\"\n",
    "print(features_path,\"\\n\",label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fb2df7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train_path = f\"{tag}/dt={str(date.today())}/preprocessed/x_train.csv\"\n",
    "x_test_path = f\"{tag}/dt={str(date.today())}/preprocessed/x_test.csv\"\n",
    "y_train_path = f\"{tag}/dt={str(date.today())}/preprocessed/y_train.csv\"\n",
    "y_test_path = f\"{tag}/dt={str(date.today())}/preprocessed/y_test.csv\"\n",
    "print(x_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7daa91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obj = s3_client.get_object(Bucket=repo_name, Key=x_train_path)\n",
    "x_train = pd.read_csv(io.BytesIO(obj['Body'].read()), header='infer')\n",
    "x_train.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2cb63f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obj = s3_client.get_object(Bucket=repo_name, Key=x_test_path)\n",
    "x_test = pd.read_csv(io.BytesIO(obj['Body'].read()), header='infer')\n",
    "x_test.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9a96ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obj = s3_client.get_object(Bucket=repo_name, Key=y_train_path)\n",
    "y_train = pd.read_csv(io.BytesIO(obj['Body'].read()), header='infer')\n",
    "y_train.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8e1e71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obj = s3_client.get_object(Bucket=repo_name, Key=y_test_path)\n",
    "y_test = pd.read_csv(io.BytesIO(obj['Body'].read()), header='infer')\n",
    "y_test.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5ead57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obj = s3_client.get_object(Bucket=repo_name, Key=features_path)\n",
    "features = pd.read_csv(io.BytesIO(obj['Body'].read()), header='infer')\n",
    "features.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46c2641",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obj = s3_client.get_object(Bucket=repo_name, Key=label_path)\n",
    "label = pd.read_csv(io.BytesIO(obj['Body'].read()), header='infer')\n",
    "label.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61328a88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_file = os.path.join(f\"s3://{repo_name}/{tag}/dt={str(date.today())}/artifacts/\", \"model.joblib\")\n",
    "print(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844b9a28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read\n",
    "with s3.open(output_file, 'rb') as f:\n",
    "    rf = joblib.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b68161b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_predict=rf.predict(x_test)\n",
    "\n",
    "rf_conf_matrix = confusion_matrix(y_test, rf_predict)\n",
    "rf_f1_score = f1_score(y_test, rf_predict, average=params1['f1_average'])\n",
    "print(rf_conf_matrix)\n",
    "print(\"\\nF1-score: \\t\", round(rf_f1_score*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e01c121-4c40-43da-ac74-3dc650cdb975",
   "metadata": {
    "tags": []
   },
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67002a0d-0d8c-4191-9844-3a3348349fde",
   "metadata": {},
   "source": [
    "## More Questions?\n",
    "\n",
    "###### Join the lakeFS Slack group - https://lakefs.io/slack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521c23a6-5187-4183-add2-91a4bd210cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
