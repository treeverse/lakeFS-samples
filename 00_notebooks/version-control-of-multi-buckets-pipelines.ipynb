{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa57f546-d5f8-4735-9157-42a9ea85de34",
   "metadata": {},
   "source": [
    "<img src=\"./images/logo.svg\" alt=\"lakeFS logo\" width=300/> \n",
    "\n",
    "# Version Control of multi-buckets pipelines\n",
    "\n",
    "In data engineering pipelines, it is common to have distinct buckets that serve different purposes. These buckets are typically named and categorized based on their respective stages in the data processing pipeline.\n",
    "\n",
    "When implementing lakeFS, it may be necessary to maintain separate physical buckets for each stage. However, it is important to version control all changes made to each bucket and link between different versions to track the evolution of the data through the pipeline.\n",
    "\n",
    "To achieve this, lakeFS enables you to create and manage repositories for each bucket stage, ensuring all changes are version-controlled. In this demo, you will learn how to set up these repositories, merge branches, and link different versions to seamlessly promote data through the pipeline stages. This approach offers a robust version control system that ensures comprehensive data lineage and auditing of transformations across all stages of the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd3e12d-be3e-4a7d-864a-196c6ec1e941",
   "metadata": {},
   "source": [
    "![Multi-bucket Pipelines](./images/version-control-of-multi-buckets-pipelines/MultiBucketsPipelines.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b339b99",
   "metadata": {},
   "source": [
    "## Config\n",
    "\n",
    "**_If you're not using the provided lakeFS server and MinIO storage then change these values to match your environment_**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c618f0",
   "metadata": {},
   "source": [
    "### lakeFS endpoint and credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835f510a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lakefsEndPoint = 'http://lakefs:8000' # e.g. 'https://username.aws_region_name.lakefscloud.io' \n",
    "lakefsAccessKey = 'AKIAIOSFOLKFSSAMPLES'\n",
    "lakefsSecretKey = 'wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cf2029",
   "metadata": {},
   "source": [
    "### Object Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871bdea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "baseStorageNamespace = 's3://example' # e.g. \"s3://bucket\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315ef41d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f668de",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "**(you shouldn't need to change anything in this section, just run it)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de09928-c6d8-45b5-a4d1-ca599d98bb8a",
   "metadata": {},
   "source": [
    "### Versioning Information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c2cfd5-2c67-44a3-bbc4-d014fcda2fe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repoPrefix = \"multi-bucket-demo\"\n",
    "mainBranch = \"main\"\n",
    "\n",
    "bronzeIngestionBranch = \"bronze-ingestion\"\n",
    "silverETLBranch = \"silver-etl\"\n",
    "silverDataPath = \"silver_data\"\n",
    "\n",
    "fileName = \"lakefs_test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3678c203-e25a-462f-96ac-d89a6317efeb",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fc50db-07bd-401f-a5c8-50eaaad72d45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import lakefs\n",
    "from assets.lakefs_demo import print_commit, print_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93007fa6-3349-4689-bc21-c1f891b9f700",
   "metadata": {},
   "source": [
    "### Set environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8ff3eb-d6a8-4029-a06c-b18a609b48d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"LAKECTL_SERVER_ENDPOINT_URL\"] = lakefsEndPoint\n",
    "os.environ[\"LAKECTL_CREDENTIALS_ACCESS_KEY_ID\"] = lakefsAccessKey\n",
    "os.environ[\"LAKECTL_CREDENTIALS_SECRET_ACCESS_KEY\"] = lakefsSecretKey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1087cfa-9b73-4e58-939c-948df7be78f3",
   "metadata": {},
   "source": [
    "### Define lakeFS UI Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec91e02-6ef1-4adc-829a-0760c0fc9c0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if lakefsEndPoint.startswith('http://host.docker.internal'):\n",
    "    lakefsUIEndPoint = 'http://127.0.0.1:8000'\n",
    "elif lakefsEndPoint.startswith('http://lakefs:8000'):\n",
    "    lakefsUIEndPoint = 'http://127.0.0.1:8000'\n",
    "else:\n",
    "    lakefsUIEndPoint = lakefsEndPoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6523b27",
   "metadata": {},
   "source": [
    "### Verify lakeFS credentials by getting lakeFS version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4a3a20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Verifying lakeFS credentials‚Ä¶\")\n",
    "try:\n",
    "    v=lakefs.client.Client().version\n",
    "except:\n",
    "    print(\"üõë failed to get lakeFS version\")\n",
    "else:\n",
    "    print(f\"‚Ä¶‚úÖlakeFS credentials verified\\n\\n‚ÑπÔ∏èlakeFS version {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a3984a",
   "metadata": {},
   "source": [
    "### Set up Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8857019f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"lakeFS / Jupyter\") \\\n",
    "                    .config(\"spark.hadoop.fs.s3.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "                    .config(\"spark.hadoop.fs.s3a.endpoint\", lakefsEndPoint) \\\n",
    "                    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "                    .config(\"spark.hadoop.fs.s3a.access.key\", lakefsAccessKey) \\\n",
    "                    .config(\"spark.hadoop.fs.s3a.secret.key\", lakefsSecretKey) \\\n",
    "                    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.3.0\") \\\n",
    "                    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "                    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "                    .config(\"spark.delta.logStore.class\", \"org.apache.spark.sql.delta.storage.S3SingleDriverLogStore\") \\\n",
    "                    .getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"INFO\")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014582ff",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bac8f53",
   "metadata": {},
   "source": [
    "# Main demo starts here üö¶ üëáüèª"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76730cdd",
   "metadata": {},
   "source": [
    "## Change the environment variable. It can be either dev, qa or prod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c13379-da71-4eab-9ca0-d3b301ab8249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "environment = 'dev'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0ae16c-b33f-472c-a674-8c48a8e1f9e3",
   "metadata": {},
   "source": [
    "## Storage Information for the Bronze (landing / raw) repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c4e5f9-1ba3-44bf-8b17-d53cf8f3b794",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bronzeRepo = environment + \"-bronze\"\n",
    "bronzeRepoStorageNamespace = f\"{baseStorageNamespace}/{repoPrefix}-{environment}-bronze\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3ae228-fe65-48e1-a526-5ca4151b52d5",
   "metadata": {},
   "source": [
    "## Storage Information for the silver repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2402e90f-460b-4e82-9ab4-55999c23011b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "silverRepo = environment + \"-silver\"\n",
    "silverRepoStorageNamespace = f\"{baseStorageNamespace}/{repoPrefix}-{environment}-silver\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd3fc83-31d6-4d96-97e4-df2ce25a6594",
   "metadata": {},
   "source": [
    "## Storage Information for the Gold (curated / final) bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d930ba7-e1f8-4400-a7f6-ae14cc208be1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "goldBucketName = f\"{baseStorageNamespace}/{repoPrefix}-{environment}-gold\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344aeba6-88b7-4ca4-8663-f0e7f50afcb4",
   "metadata": {},
   "source": [
    "## Create Bronze (landing / raw) repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59184c81-88f5-40ac-81c6-fb275ca30b23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repoBronze = lakefs.Repository(bronzeRepo).create(storage_namespace=bronzeRepoStorageNamespace, default_branch=mainBranch, exist_ok=True)\n",
    "repoBronzeBranchMain = repoBronze.branch(mainBranch)\n",
    "print(repoBronze)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7aa82d6-8dad-422d-9a70-b2fdd7aa50a1",
   "metadata": {},
   "source": [
    "## Create silver repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29fec72-98e9-4f2e-960f-a652d88138ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repoSilver = lakefs.Repository(silverRepo).create(storage_namespace=silverRepoStorageNamespace, default_branch=mainBranch, exist_ok=True)\n",
    "print(repoSilver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3bfa3a-8d44-4384-aaae-657355122a47",
   "metadata": {},
   "source": [
    "## Create Ingestion branch in the Bronze repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79e69f6-1728-4d35-85aa-88b97b3de811",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "branchBronzeIngestion = repoBronze.branch(bronzeIngestionBranch).create(source_reference=mainBranch)\n",
    "print(f\"{bronzeIngestionBranch} ref:\", branchBronzeIngestion.get_commit().id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ecfb65-c4ce-41f1-8a05-b60b58b3859b",
   "metadata": {},
   "source": [
    "## Upload a file to the Ingestion branch in the Bronze repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f965d40f-2770-412a-8e79-37bd067e8da1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "contentToUpload = open(f\"/data/{fileName}\", 'r').read()\n",
    "branchBronzeIngestion.object(fileName).upload(data=contentToUpload, mode='wb', pre_sign=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b9beda-1e9a-4548-84bd-236985705b0f",
   "metadata": {},
   "source": [
    "## Commit changes and attach data classification, source and target in the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a43653-056b-417e-b24f-767d05ceadaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataClassification = 'raw-green'\n",
    "source = 'bronze'\n",
    "target = lakefsUIEndPoint + '/repositories/' + bronzeRepo + '/object?ref=' + bronzeIngestionBranch + '&path=' + fileName\n",
    "\n",
    "ref = branchBronzeIngestion.commit(\n",
    "        message='Added my first file in ' + bronzeRepo + ' repository!',\n",
    "        metadata={'using': 'python_api',\n",
    "                  'data classification': dataClassification,\n",
    "                  '::lakefs::source::url[url:ui]': source,\n",
    "                  '::lakefs::target::url[url:ui]': target})\n",
    "print_commit(ref.get_commit())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd26af74-6bb7-4ef8-b4c5-9565d8a66ee3",
   "metadata": {},
   "source": [
    "## Merge ingestion branch to the main branch if upload succeeds (atomic promotion to production)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3adc90-65e2-4ad6-beb8-bb50962d4807",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = branchBronzeIngestion.merge_into(mainBranch)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46df0d7-3ef3-4016-b227-c4a7e60f5771",
   "metadata": {},
   "source": [
    "## Reading data from the Main branch of the Bronze repo by using an S3A Gateway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765cd354-832e-4b06-9417-405dc7bda4e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataPath = f\"s3a://{bronzeRepo}/{mainBranch}/{fileName}\"\n",
    "\n",
    "df = spark.read.csv(dataPath)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03a6535-cfe7-428a-b602-52a3840e8de2",
   "metadata": {},
   "source": [
    "## Get commit information from the Bronze (landing / raw) repo for the source file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b49980-d79f-4faf-a1ba-226e50991a12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bronzeCommits = list(repoBronzeBranchMain.log(max_amount=1, objects=[fileName]))\n",
    "print_commit(bronzeCommits[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b78583b-efa1-4f6b-8bd5-7fd9895c9d28",
   "metadata": {},
   "source": [
    "## Create ETL branch in the silver repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0f906e-529c-41a2-aa46-88d6258c7194",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "branchSilverETL = repoSilver.branch(silverETLBranch).create(source_reference=mainBranch)\n",
    "print(f\"{silverETLBranch} ref:\", branchSilverETL.get_commit().id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59900208-6366-454d-bc10-65b06c613a52",
   "metadata": {},
   "source": [
    "## Partition the data and write to ETL branch of the silver (Stage / Transformed) repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b7103b-c550-442a-822e-589657fd3079",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "newDataPath = f\"s3a://{silverRepo}/{silverETLBranch}/{silverDataPath}\"\n",
    "\n",
    "df.write.partitionBy(\"_c0\").mode(\"overwrite\").csv(newDataPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347ef53f-3902-47d7-abe5-e15db10a3d96",
   "metadata": {},
   "source": [
    "## Commit changes and attach data classification, source, source commit and target in the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3480497-78f7-4d96-b57a-5ce4335986f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataClassification = 'transformed-green'\n",
    "source = lakefsUIEndPoint + '/repositories/' + bronzeRepo + '/object?ref=' + mainBranch + '&path=' + fileName\n",
    "source_commit =  lakefsUIEndPoint + '/repositories/' + bronzeRepo + '/commits/' + bronzeCommits[0].id\n",
    "target = lakefsUIEndPoint + '/repositories/' + silverRepo + '/objects?ref=' + silverETLBranch + '&path=' + silverDataPath + '/'\n",
    "\n",
    "ref = branchSilverETL.commit(\n",
    "        message='Added transformed data in ' + silverRepo + ' repository!',\n",
    "        metadata={'using': 'python_api',\n",
    "                 'data classification': dataClassification,\n",
    "                  '::lakefs::source::url[url:ui]': source,\n",
    "                  '::lakefs::source_commit::url[url:ui]': source_commit,\n",
    "                  '::lakefs::target::url[url:ui]': target})\n",
    "print_commit(ref.get_commit())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0269feba-80dd-4ddc-871a-67a0b0197a23",
   "metadata": {},
   "source": [
    "## Merge ETL branch to the main branch in the silver repo if the ETL succeeds (atomic promotion to production)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fc05ff-7f25-438e-b1c3-031fc04b41ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = branchSilverETL.merge_into(mainBranch)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b852e50c-cce5-4201-a949-a0f73a97a7cc",
   "metadata": {},
   "source": [
    "## Export Data\n",
    "### Exporting data from lakeFS can be done in various ways, but one simple method is to use Docker: https://docs.lakefs.io/howto/export.html\n",
    "#### Change AWS access key and secret key\n",
    "#### Run printed command in the macOS Terminal or Windows Command Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7afa2fd-dd36-4960-8615-bb28bf15b795",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\n",
    "'docker run -e LAKEFS_ACCESS_KEY_ID=' + lakefsAccessKey + ' \\\n",
    "-e LAKEFS_SECRET_ACCESS_KEY=' + lakefsSecretKey + ' \\\n",
    "-e LAKEFS_ENDPOINT=' + lakefsEndPoint + ' \\\n",
    "-e AWS_ACCESS_KEY_ID=aaaaaaaaaaaaa \\\n",
    "-e AWS_SECRET_ACCESS_KEY=bbbbbbbbbbbbbbbbbb \\\n",
    "-it treeverse/lakefs-rclone-export:latest ' + environment + '-silver ' + goldBucketName + '/main/ --branch=main'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cfd057-897b-4b23-8600-c5a95b6daaf7",
   "metadata": {},
   "source": [
    "## More Questions?\n",
    "\n",
    "###### Join the lakeFS Slack group - https://lakefs.io/slack"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
